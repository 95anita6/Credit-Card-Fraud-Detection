{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective : Predict if the given transaction is fraudulent or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = r'C:\\Users\\AnitaM\\Downloads\\creditcard\\creditcard.csv'\n",
    "cc = pd.read_csv(fname)\n",
    "cc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      float64\n",
       "V1        float64\n",
       "V2        float64\n",
       "V3        float64\n",
       "V4        float64\n",
       "V5        float64\n",
       "V6        float64\n",
       "V7        float64\n",
       "V8        float64\n",
       "V9        float64\n",
       "V10       float64\n",
       "V11       float64\n",
       "V12       float64\n",
       "V13       float64\n",
       "V14       float64\n",
       "V15       float64\n",
       "V16       float64\n",
       "V17       float64\n",
       "V18       float64\n",
       "V19       float64\n",
       "V20       float64\n",
       "V21       float64\n",
       "V22       float64\n",
       "V23       float64\n",
       "V24       float64\n",
       "V25       float64\n",
       "V26       float64\n",
       "V27       float64\n",
       "V28       float64\n",
       "Amount    float64\n",
       "Class       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize the data to pass it to neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features :  (284807, 30)\n",
      "Shape of labels :  (284807,)\n"
     ]
    }
   ],
   "source": [
    "cc_features = cc.copy()\n",
    "cc_labels = cc_features.pop('Class')\n",
    "\n",
    "print('Shape of features : ', cc_features.shape)\n",
    "print('Shape of labels : ', cc_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_testing = np.array(cc_labels, dtype='int64')\n",
    "targets_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = []\n",
    "all_targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n"
     ]
    }
   ],
   "source": [
    "with open(fname) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(\"HEADER:\", line.strip())\n",
    "            continue  # Skip header\n",
    "        fields = line.strip().split(\",\")\n",
    "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
    "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        if i == 1:\n",
    "            print(\"EXAMPLE FEATURES:\", all_features[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape: (284807, 30)\n",
      "targets.shape: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "features = np.array(all_features, dtype=\"float32\")\n",
    "targets = np.array(all_targets, dtype=\"uint8\")\n",
    "print(\"features.shape:\", features.shape)\n",
    "print(\"targets.shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 227846\n",
      "Number of validation samples: 56961\n"
     ]
    }
   ],
   "source": [
    "num_val_samples = int(len(features) * 0.2)\n",
    "train_features = features[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_features = features[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]\n",
    "\n",
    "print(\"Number of training samples:\", len(train_features))\n",
    "print(\"Number of validation samples:\", len(val_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze class imbalance in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 417 (0.18% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(train_targets[:, 0])\n",
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the data using training set statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a binary classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               7936      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 139,777\n",
      "Trainable params: 139,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            256, activation=\"relu\", input_shape=(train_features.shape[-1],)\n",
    "        ),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model with class_weight argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 227846 samples, validate on 56961 samples\n",
      "Epoch 1/30\n",
      "227846/227846 - 111s - loss: 2.0977e-06 - fn: 45.0000 - fp: 18774.0000 - tn: 208655.0000 - tp: 372.0000 - precision: 0.0194 - recall: 0.8921 - val_loss: 1.2587e-06 - val_fn: 7.0000 - val_fp: 2658.0000 - val_tn: 54228.0000 - val_tp: 68.0000 - val_precision: 0.0249 - val_recall: 0.9067\n",
      "Epoch 2/30\n",
      "227846/227846 - 17s - loss: 1.5965e-06 - fn: 37.0000 - fp: 12501.0000 - tn: 214928.0000 - tp: 380.0000 - precision: 0.0295 - recall: 0.9113 - val_loss: 1.0043e-06 - val_fn: 9.0000 - val_fp: 1523.0000 - val_tn: 55363.0000 - val_tp: 66.0000 - val_precision: 0.0415 - val_recall: 0.8800\n",
      "Epoch 3/30\n",
      "227846/227846 - 14s - loss: 1.1091e-06 - fn: 27.0000 - fp: 8073.0000 - tn: 219356.0000 - tp: 390.0000 - precision: 0.0461 - recall: 0.9353 - val_loss: 1.0506e-06 - val_fn: 9.0000 - val_fp: 666.0000 - val_tn: 56220.0000 - val_tp: 66.0000 - val_precision: 0.0902 - val_recall: 0.8800\n",
      "Epoch 4/30\n",
      "227846/227846 - 14s - loss: 9.9642e-07 - fn: 27.0000 - fp: 6805.0000 - tn: 220624.0000 - tp: 390.0000 - precision: 0.0542 - recall: 0.9353 - val_loss: 1.2551e-06 - val_fn: 7.0000 - val_fp: 897.0000 - val_tn: 55989.0000 - val_tp: 68.0000 - val_precision: 0.0705 - val_recall: 0.9067\n",
      "Epoch 5/30\n",
      "227846/227846 - 14s - loss: 9.4630e-07 - fn: 21.0000 - fp: 6771.0000 - tn: 220658.0000 - tp: 396.0000 - precision: 0.0553 - recall: 0.9496 - val_loss: 1.1409e-06 - val_fn: 7.0000 - val_fp: 1034.0000 - val_tn: 55852.0000 - val_tp: 68.0000 - val_precision: 0.0617 - val_recall: 0.9067\n",
      "Epoch 6/30\n",
      "227846/227846 - 15s - loss: 8.3840e-07 - fn: 19.0000 - fp: 7397.0000 - tn: 220032.0000 - tp: 398.0000 - precision: 0.0511 - recall: 0.9544 - val_loss: 1.0774e-06 - val_fn: 6.0000 - val_fp: 3211.0000 - val_tn: 53675.0000 - val_tp: 69.0000 - val_precision: 0.0210 - val_recall: 0.9200\n",
      "Epoch 7/30\n",
      "227846/227846 - 13s - loss: 6.5939e-07 - fn: 14.0000 - fp: 6609.0000 - tn: 220820.0000 - tp: 403.0000 - precision: 0.0575 - recall: 0.9664 - val_loss: 1.3805e-06 - val_fn: 9.0000 - val_fp: 1176.0000 - val_tn: 55710.0000 - val_tp: 66.0000 - val_precision: 0.0531 - val_recall: 0.8800\n",
      "Epoch 8/30\n",
      "227846/227846 - 13s - loss: 8.6656e-07 - fn: 16.0000 - fp: 7591.0000 - tn: 219838.0000 - tp: 401.0000 - precision: 0.0502 - recall: 0.9616 - val_loss: 1.6388e-06 - val_fn: 9.0000 - val_fp: 1044.0000 - val_tn: 55842.0000 - val_tp: 66.0000 - val_precision: 0.0595 - val_recall: 0.8800\n",
      "Epoch 9/30\n",
      "227846/227846 - 15s - loss: 1.0038e-06 - fn: 16.0000 - fp: 8247.0000 - tn: 219182.0000 - tp: 401.0000 - precision: 0.0464 - recall: 0.9616 - val_loss: 1.8804e-06 - val_fn: 9.0000 - val_fp: 695.0000 - val_tn: 56191.0000 - val_tp: 66.0000 - val_precision: 0.0867 - val_recall: 0.8800\n",
      "Epoch 10/30\n",
      "227846/227846 - 14s - loss: 1.3733e-06 - fn: 18.0000 - fp: 9140.0000 - tn: 218289.0000 - tp: 399.0000 - precision: 0.0418 - recall: 0.9568 - val_loss: 1.1556e-06 - val_fn: 9.0000 - val_fp: 988.0000 - val_tn: 55898.0000 - val_tp: 66.0000 - val_precision: 0.0626 - val_recall: 0.8800\n",
      "Epoch 11/30\n",
      "227846/227846 - 13s - loss: 7.0510e-07 - fn: 13.0000 - fp: 5926.0000 - tn: 221503.0000 - tp: 404.0000 - precision: 0.0638 - recall: 0.9688 - val_loss: 1.2110e-06 - val_fn: 7.0000 - val_fp: 984.0000 - val_tn: 55902.0000 - val_tp: 68.0000 - val_precision: 0.0646 - val_recall: 0.9067\n",
      "Epoch 12/30\n",
      "227846/227846 - 13s - loss: 6.0864e-07 - fn: 6.0000 - fp: 5973.0000 - tn: 221456.0000 - tp: 411.0000 - precision: 0.0644 - recall: 0.9856 - val_loss: 2.0053e-06 - val_fn: 12.0000 - val_fp: 417.0000 - val_tn: 56469.0000 - val_tp: 63.0000 - val_precision: 0.1312 - val_recall: 0.8400\n",
      "Epoch 13/30\n",
      "227846/227846 - 13s - loss: 7.2967e-07 - fn: 12.0000 - fp: 7022.0000 - tn: 220407.0000 - tp: 405.0000 - precision: 0.0545 - recall: 0.9712 - val_loss: 1.9085e-06 - val_fn: 8.0000 - val_fp: 1209.0000 - val_tn: 55677.0000 - val_tp: 67.0000 - val_precision: 0.0525 - val_recall: 0.8933\n",
      "Epoch 14/30\n",
      "227846/227846 - 13s - loss: 5.5857e-07 - fn: 7.0000 - fp: 6498.0000 - tn: 220931.0000 - tp: 410.0000 - precision: 0.0594 - recall: 0.9832 - val_loss: 2.3171e-06 - val_fn: 9.0000 - val_fp: 659.0000 - val_tn: 56227.0000 - val_tp: 66.0000 - val_precision: 0.0910 - val_recall: 0.8800\n",
      "Epoch 15/30\n",
      "227846/227846 - 14s - loss: 5.0328e-07 - fn: 7.0000 - fp: 4994.0000 - tn: 222435.0000 - tp: 410.0000 - precision: 0.0759 - recall: 0.9832 - val_loss: 2.9262e-06 - val_fn: 9.0000 - val_fp: 748.0000 - val_tn: 56138.0000 - val_tp: 66.0000 - val_precision: 0.0811 - val_recall: 0.8800\n",
      "Epoch 16/30\n",
      "227846/227846 - 13s - loss: 1.6273e-06 - fn: 14.0000 - fp: 8339.0000 - tn: 219090.0000 - tp: 403.0000 - precision: 0.0461 - recall: 0.9664 - val_loss: 2.0864e-06 - val_fn: 11.0000 - val_fp: 341.0000 - val_tn: 56545.0000 - val_tp: 64.0000 - val_precision: 0.1580 - val_recall: 0.8533\n",
      "Epoch 17/30\n",
      "227846/227846 - 15s - loss: 9.0571e-07 - fn: 14.0000 - fp: 6080.0000 - tn: 221349.0000 - tp: 403.0000 - precision: 0.0622 - recall: 0.9664 - val_loss: 2.0911e-06 - val_fn: 9.0000 - val_fp: 1574.0000 - val_tn: 55312.0000 - val_tp: 66.0000 - val_precision: 0.0402 - val_recall: 0.8800\n",
      "Epoch 18/30\n",
      "227846/227846 - 14s - loss: 6.0839e-07 - fn: 7.0000 - fp: 4015.0000 - tn: 223414.0000 - tp: 410.0000 - precision: 0.0927 - recall: 0.9832 - val_loss: 2.2085e-06 - val_fn: 11.0000 - val_fp: 233.0000 - val_tn: 56653.0000 - val_tp: 64.0000 - val_precision: 0.2155 - val_recall: 0.8533\n",
      "Epoch 19/30\n",
      "227846/227846 - 14s - loss: 4.4583e-07 - fn: 6.0000 - fp: 4290.0000 - tn: 223139.0000 - tp: 411.0000 - precision: 0.0874 - recall: 0.9856 - val_loss: 2.7003e-06 - val_fn: 10.0000 - val_fp: 817.0000 - val_tn: 56069.0000 - val_tp: 65.0000 - val_precision: 0.0737 - val_recall: 0.8667\n",
      "Epoch 20/30\n",
      "227846/227846 - 13s - loss: 3.6595e-07 - fn: 5.0000 - fp: 4125.0000 - tn: 223304.0000 - tp: 412.0000 - precision: 0.0908 - recall: 0.9880 - val_loss: 2.9791e-06 - val_fn: 9.0000 - val_fp: 471.0000 - val_tn: 56415.0000 - val_tp: 66.0000 - val_precision: 0.1229 - val_recall: 0.8800\n",
      "Epoch 21/30\n",
      "227846/227846 - 14s - loss: 2.9672e-07 - fn: 4.0000 - fp: 3452.0000 - tn: 223977.0000 - tp: 413.0000 - precision: 0.1069 - recall: 0.9904 - val_loss: 2.2877e-06 - val_fn: 6.0000 - val_fp: 1862.0000 - val_tn: 55024.0000 - val_tp: 69.0000 - val_precision: 0.0357 - val_recall: 0.9200\n",
      "Epoch 22/30\n",
      "227846/227846 - 14s - loss: 2.4228e-07 - fn: 1.0000 - fp: 2922.0000 - tn: 224507.0000 - tp: 416.0000 - precision: 0.1246 - recall: 0.9976 - val_loss: 4.6886e-06 - val_fn: 10.0000 - val_fp: 291.0000 - val_tn: 56595.0000 - val_tp: 65.0000 - val_precision: 0.1826 - val_recall: 0.8667\n",
      "Epoch 23/30\n",
      "227846/227846 - 15s - loss: 3.7837e-07 - fn: 3.0000 - fp: 3941.0000 - tn: 223488.0000 - tp: 414.0000 - precision: 0.0951 - recall: 0.9928 - val_loss: 3.3316e-06 - val_fn: 11.0000 - val_fp: 433.0000 - val_tn: 56453.0000 - val_tp: 64.0000 - val_precision: 0.1288 - val_recall: 0.8533\n",
      "Epoch 24/30\n",
      "227846/227846 - 14s - loss: 2.5554e-07 - fn: 1.0000 - fp: 3018.0000 - tn: 224411.0000 - tp: 416.0000 - precision: 0.1211 - recall: 0.9976 - val_loss: 4.7413e-06 - val_fn: 11.0000 - val_fp: 406.0000 - val_tn: 56480.0000 - val_tp: 64.0000 - val_precision: 0.1362 - val_recall: 0.8533\n",
      "Epoch 25/30\n",
      "227846/227846 - 14s - loss: 6.6839e-07 - fn: 6.0000 - fp: 5304.0000 - tn: 222125.0000 - tp: 411.0000 - precision: 0.0719 - recall: 0.9856 - val_loss: 3.3568e-06 - val_fn: 5.0000 - val_fp: 3909.0000 - val_tn: 52977.0000 - val_tp: 70.0000 - val_precision: 0.0176 - val_recall: 0.9333\n",
      "Epoch 26/30\n",
      "227846/227846 - 13s - loss: 1.2198e-06 - fn: 14.0000 - fp: 5869.0000 - tn: 221560.0000 - tp: 403.0000 - precision: 0.0643 - recall: 0.9664 - val_loss: 1.7747e-06 - val_fn: 9.0000 - val_fp: 604.0000 - val_tn: 56282.0000 - val_tp: 66.0000 - val_precision: 0.0985 - val_recall: 0.8800\n",
      "Epoch 27/30\n",
      "227846/227846 - 14s - loss: 6.8775e-07 - fn: 4.0000 - fp: 5902.0000 - tn: 221527.0000 - tp: 413.0000 - precision: 0.0654 - recall: 0.9904 - val_loss: 1.8453e-06 - val_fn: 8.0000 - val_fp: 593.0000 - val_tn: 56293.0000 - val_tp: 67.0000 - val_precision: 0.1015 - val_recall: 0.8933\n",
      "Epoch 28/30\n",
      "227846/227846 - 14s - loss: 3.5600e-07 - fn: 5.0000 - fp: 3742.0000 - tn: 223687.0000 - tp: 412.0000 - precision: 0.0992 - recall: 0.9880 - val_loss: 2.6329e-06 - val_fn: 10.0000 - val_fp: 366.0000 - val_tn: 56520.0000 - val_tp: 65.0000 - val_precision: 0.1508 - val_recall: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "227846/227846 - 13s - loss: 2.7340e-07 - fn: 1.0000 - fp: 3349.0000 - tn: 224080.0000 - tp: 416.0000 - precision: 0.1105 - recall: 0.9976 - val_loss: 4.6196e-06 - val_fn: 11.0000 - val_fp: 228.0000 - val_tn: 56658.0000 - val_tp: 64.0000 - val_precision: 0.2192 - val_recall: 0.8533\n",
      "Epoch 30/30\n",
      "227846/227846 - 13s - loss: 3.8658e-07 - fn: 2.0000 - fp: 2663.0000 - tn: 224766.0000 - tp: 415.0000 - precision: 0.1348 - recall: 0.9952 - val_loss: 4.4903e-06 - val_fn: 11.0000 - val_fp: 332.0000 - val_tn: 56554.0000 - val_tp: 64.0000 - val_precision: 0.1616 - val_recall: 0.8533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xbec18acf98>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=2048,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(val_features, val_targets),\n",
    "    class_weight=class_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the real world, even higher weight can be assigned to class 1, so as to reflect that False Negatives are more costly than False Positives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
